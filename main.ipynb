{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !git lfs install || true\n",
    "# !pip -q install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/huggingface/diffusers\n",
    "%cd diffusers\n",
    "!pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -r examples/dreambooth/requirements_sana.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q \"peft>=0.14.0\"\n",
    "!pip install -q accelerate transformers datasets huggingface_hub safetensors wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate.utils import write_basic_config\n",
    "\n",
    "write_basic_config()\n",
    "print(\"Wrote default accelerate config.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This script downloads the Naruto BLIP Captions dataset from Hugging Face\n",
    "# and saves the images and captions to a local directory.\n",
    "# Requirements: Run in a Python environment with the following libraries installed:\n",
    "# pip install datasets pillow\n",
    "\n",
    "import os\n",
    "from datasets import load_dataset\n",
    "from PIL import Image  # For saving images\n",
    "\n",
    "# Load the dataset from Hugging Face\n",
    "dataset = load_dataset(\"lambdalabs/naruto-blip-captions\")\n",
    "\n",
    "# Create a directory to save the dataset\n",
    "save_dir = \"naruto_dataset\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "# The dataset has a 'train' split with images and captions\n",
    "# Iterate through the dataset and save each image and its caption\n",
    "for idx, item in enumerate(dataset['train']):\n",
    "    # Save the image\n",
    "    image_path = os.path.join(save_dir, f\"image_{idx:04d}.jpg\")\n",
    "    item['image'].save(image_path)\n",
    "    \n",
    "    # Save the caption to a text file\n",
    "    caption_path = os.path.join(save_dir, f\"caption_{idx:04d}.txt\")\n",
    "    with open(caption_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(item['text'])\n",
    "\n",
    "print(f\"Dataset downloaded and saved to '{save_dir}'. Total items: {len(dataset['train'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_dir = \"naruto_dataset\"\n",
    "\n",
    "# The sentence to append\n",
    "append_text = \" in Naruto Anime style.\"\n",
    "\n",
    "# Iterate through all files in the directory\n",
    "for filename in os.listdir(save_dir):\n",
    "    # Check if the file is a .txt file\n",
    "    if filename.endswith(\".txt\"):\n",
    "        file_path = os.path.join(save_dir, filename)\n",
    "        # Open the file in append mode and add the sentence\n",
    "        with open(file_path, \"a\", encoding=\"utf-8\") as f:\n",
    "            f.write(append_text)\n",
    "\n",
    "print(f\"Appended '{append_text}' to all .txt files in '{save_dir}'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gdown -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "\n",
    "# Google Drive file ID\n",
    "file_id = \"16NR1_Zvronbla7j2v4W3_xX8lpVNnEFJ\"\n",
    "\n",
    "# URL format using ID\n",
    "url = f\"https://drive.google.com/uc?id={file_id}\"\n",
    "\n",
    "# Output file name\n",
    "output = \"PPE_SANA.zip\"\n",
    "\n",
    "# Download the file\n",
    "gdown.download(url, output, quiet=False)\n",
    "\n",
    "print(f\"✅ Download completed: {output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your downloaded zip file\n",
    "zip_file = \"/teamspace/studios/this_studio/PPE_SANA.zip\"\n",
    "\n",
    "# Destination folder to extract\n",
    "extract_folder = \"/teamspace/studios/this_studio/PPE_SANA\"\n",
    "\n",
    "# Unzip the file\n",
    "!unzip -q {zip_file} -d {extract_folder}\n",
    "\n",
    "print(f\"✅ Zip file extracted to: {extract_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/teamspace/studios/this_studio/diffusers/examples/dreambooth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zeus/miniconda3/envs/cloudspace/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: using dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "%cd diffusers/examples/dreambooth/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# print(torch.cuda.is_available())\n",
    "# print(torch.cuda.device_count())\n",
    "# print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "09/20/2025 18:38:46 - INFO - __main__ - Distributed environment: NO\n",
      "Num processes: 1\n",
      "Process index: 0\n",
      "Local process index: 0\n",
      "Device: cuda\n",
      "\n",
      "Mixed precision type: bf16\n",
      "\n",
      "{'base_shift', 'time_shift_type', 'max_image_seq_len', 'invert_sigmas', 'stochastic_sampling', 'use_dynamic_shifting', 'shift', 'base_image_seq_len', 'shift_terminal', 'max_shift'} was not found in config. Values will be initialized to default values.\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.46s/it]\n",
      "{'decoder_conv_act_fn', 'decoder_in_shortcut', 'encoder_out_shortcut'} was not found in config. Values will be initialized to default values.\n",
      "All model checkpoint weights were used when initializing AutoencoderDC.\n",
      "\n",
      "All the weights of AutoencoderDC were initialized from the model checkpoint at Efficient-Large-Model/Sana_1600M_1024px_diffusers.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderDC for predictions without further training.\n",
      "Fetching 2 files: 100%|████████████████████████| 2/2 [00:00<00:00, 31536.12it/s]\n",
      "{'interpolation_scale', 'guidance_embeds_scale', 'timestep_scale', 'guidance_embeds', 'qk_norm'} was not found in config. Values will be initialized to default values.\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:00<00:00, 57.95it/s]\n",
      "All model checkpoint weights were used when initializing SanaTransformer2DModel.\n",
      "\n",
      "All the weights of SanaTransformer2DModel were initialized from the model checkpoint at Efficient-Large-Model/Sana_1600M_1024px_diffusers.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use SanaTransformer2DModel for predictions without further training.\n",
      "Loading pipeline components...:   0%|                     | 0/3 [00:00<?, ?it/s]{'use_dynamic_shifting', 'time_shift_type'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as DPMSolverMultistepScheduler from `scheduler` subfolder of Efficient-Large-Model/Sana_1600M_1024px_diffusers.\n",
      "Loading pipeline components...: 100%|████████████| 3/3 [00:00<00:00, 454.31it/s]\n",
      "[DEBUG] Using per-image captions. Example: ['The worker is engaged in maintenance or installation tasks on high voltage electrical equipment. Wearing a red helmet, gloves, and a safety vest, they are handling insulators and electrical connections. The machine or tools in use are insulator attachments, and the clear blue sky suggests an outdoor work environment. The equipment appears to be on a scaffold, emphasizing the need for PPE for safety.', 'A worker is engaged in maintenance on a piece of equipment from inside a yellow高空 lift with the text \"高空作业\" (general term for height work) on the side. The worker is wearing a red helmet, high-visibility safety vest, gloves, and jeans. The PPE appears to be appropriate for the task, though no mask is visible. The setting appears to be a construction or industrial environment, involving construction work and machinery handling.', 'In the image, the worker is engaged in welding tasks at a boiling equipment manufacturing factory. The machine in use appears to be a welding machine, emitting bright light and sparks during the welding process. The worker is wearing a red helmet, suggesting adherence to safety protocols. A mask is also part of the safety gear, helping to protect the eyes from the intense light and sparks generated by the welding.\\n\\nThe environment is an industrial workspace with large windows allowing natural light to illuminate the area. The floor looks clean and well-maintained, typical of an assembly line or welding station. The presence of safety barriers and signage in both Chinese and English (\"']\n",
      "Caching latents: 100%|██████████████████████████| 44/44 [00:07<00:00,  5.76it/s]\n",
      "09/20/2025 18:39:07 - INFO - __main__ - ***** Running training *****\n",
      "09/20/2025 18:39:07 - INFO - __main__ -   Num examples = 175\n",
      "09/20/2025 18:39:07 - INFO - __main__ -   Num batches each epoch = 44\n",
      "09/20/2025 18:39:07 - INFO - __main__ -   Num Epochs = 40\n",
      "09/20/2025 18:39:07 - INFO - __main__ -   Instantaneous batch size per device = 4\n",
      "09/20/2025 18:39:07 - INFO - __main__ -   Total train batch size (w. parallel, distributed & accumulation) = 4\n",
      "09/20/2025 18:39:07 - INFO - __main__ -   Gradient Accumulation steps = 1\n",
      "09/20/2025 18:39:07 - INFO - __main__ -   Total optimization steps = 1760\n",
      "Steps:   2%|▎             | 44/1760 [00:22<13:41,  2.09it/s, loss=1.13, lr=5e-5]\n",
      "Loading pipeline components...:   0%|                     | 0/5 [00:00<?, ?it/s]\u001b[A{'use_dynamic_shifting', 'time_shift_type'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as DPMSolverMultistepScheduler from `scheduler` subfolder of Efficient-Large-Model/Sana_1600M_1024px_diffusers.\n",
      "`torch_dtype` is deprecated! Use `dtype` instead!\n",
      "\n",
      "\n",
      "Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loading checkpoint shards:  50%|█████████         | 1/2 [00:04<00:04,  4.75s/it]\u001b[A\u001b[A\n",
      "\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.50s/it]\u001b[A\u001b[A\n",
      "Loaded text_encoder as Gemma2Model from `text_encoder` subfolder of Efficient-Large-Model/Sana_1600M_1024px_diffusers.\n",
      "\n",
      "Loading pipeline components...:  60%|███████▊     | 3/5 [00:05<00:03,  1.68s/it]\u001b[AInstantiating AutoencoderDC model under default dtype torch.float32.\n",
      "{'decoder_conv_act_fn', 'decoder_in_shortcut', 'encoder_out_shortcut'} was not found in config. Values will be initialized to default values.\n",
      "All model checkpoint weights were used when initializing AutoencoderDC.\n",
      "\n",
      "All the weights of AutoencoderDC were initialized from the model checkpoint at /teamspace/studios/this_studio/.cache/huggingface/hub/models--Efficient-Large-Model--Sana_1600M_1024px_diffusers/snapshots/d1b54936033cd7d45410ecadd692c5c502a19a38/vae.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderDC for predictions without further training.\n",
      "Loaded vae as AutoencoderDC from `vae` subfolder of Efficient-Large-Model/Sana_1600M_1024px_diffusers.\n",
      "Loaded tokenizer as GemmaTokenizerFast from `tokenizer` subfolder of Efficient-Large-Model/Sana_1600M_1024px_diffusers.\n",
      "\n",
      "Loading pipeline components...: 100%|█████████████| 5/5 [00:06<00:00,  1.23s/it]\u001b[A\n",
      "09/20/2025 18:39:36 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A worker wearing helmet, gloves, and safety vest performing maintenance on industrial equipment outdoors. The worker is handling insulators and electrical connections on high-voltage equipment, standing on scaffolding with proper PPE observed.\n",
      "Steps:  28%|███▍        | 500/1760 [04:26<10:08,  2.07it/s, loss=0.851, lr=5e-5]09/20/2025 18:43:34 - INFO - accelerate.accelerator - Saving current state to /teamspace/studios/this_studio/output_40/trained-sana-lora/checkpoint-500\n",
      "Model weights saved in /teamspace/studios/this_studio/output_40/trained-sana-lora/checkpoint-500/pytorch_lora_weights.safetensors\n",
      "09/20/2025 18:43:34 - INFO - accelerate.checkpointing - Optimizer state saved in /teamspace/studios/this_studio/output_40/trained-sana-lora/checkpoint-500/optimizer.bin\n",
      "09/20/2025 18:43:34 - INFO - accelerate.checkpointing - Scheduler state saved in /teamspace/studios/this_studio/output_40/trained-sana-lora/checkpoint-500/scheduler.bin\n",
      "09/20/2025 18:43:34 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /teamspace/studios/this_studio/output_40/trained-sana-lora/checkpoint-500/sampler.bin\n",
      "09/20/2025 18:43:34 - INFO - accelerate.checkpointing - Random states saved in /teamspace/studios/this_studio/output_40/trained-sana-lora/checkpoint-500/random_states_0.pkl\n",
      "09/20/2025 18:43:34 - INFO - __main__ - Saved state to /teamspace/studios/this_studio/output_40/trained-sana-lora/checkpoint-500\n",
      "Steps:  57%|██████▎    | 1000/1760 [08:32<06:17,  2.01it/s, loss=0.931, lr=5e-5]09/20/2025 18:47:40 - INFO - accelerate.accelerator - Saving current state to /teamspace/studios/this_studio/output_40/trained-sana-lora/checkpoint-1000\n",
      "Model weights saved in /teamspace/studios/this_studio/output_40/trained-sana-lora/checkpoint-1000/pytorch_lora_weights.safetensors\n",
      "09/20/2025 18:47:40 - INFO - accelerate.checkpointing - Optimizer state saved in /teamspace/studios/this_studio/output_40/trained-sana-lora/checkpoint-1000/optimizer.bin\n",
      "09/20/2025 18:47:40 - INFO - accelerate.checkpointing - Scheduler state saved in /teamspace/studios/this_studio/output_40/trained-sana-lora/checkpoint-1000/scheduler.bin\n",
      "09/20/2025 18:47:40 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /teamspace/studios/this_studio/output_40/trained-sana-lora/checkpoint-1000/sampler.bin\n",
      "09/20/2025 18:47:40 - INFO - accelerate.checkpointing - Random states saved in /teamspace/studios/this_studio/output_40/trained-sana-lora/checkpoint-1000/random_states_0.pkl\n",
      "09/20/2025 18:47:40 - INFO - __main__ - Saved state to /teamspace/studios/this_studio/output_40/trained-sana-lora/checkpoint-1000\n",
      "Steps:  65%|████████▍    | 1144/1760 [09:43<05:19,  1.93it/s, loss=1.3, lr=5e-5]\n",
      "Loading pipeline components...:   0%|                     | 0/5 [00:00<?, ?it/s]\u001b[A{'use_dynamic_shifting', 'time_shift_type'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as DPMSolverMultistepScheduler from `scheduler` subfolder of Efficient-Large-Model/Sana_1600M_1024px_diffusers.\n",
      "\n",
      "\n",
      "Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loading checkpoint shards:  50%|█████████         | 1/2 [00:04<00:04,  4.15s/it]\u001b[A\u001b[A\n",
      "\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:04<00:00,  2.19s/it]\u001b[A\u001b[A\n",
      "Loaded text_encoder as Gemma2Model from `text_encoder` subfolder of Efficient-Large-Model/Sana_1600M_1024px_diffusers.\n",
      "\n",
      "Loading pipeline components...:  60%|███████▊     | 3/5 [00:04<00:02,  1.47s/it]\u001b[AInstantiating AutoencoderDC model under default dtype torch.float32.\n",
      "{'decoder_conv_act_fn', 'decoder_in_shortcut', 'encoder_out_shortcut'} was not found in config. Values will be initialized to default values.\n",
      "All model checkpoint weights were used when initializing AutoencoderDC.\n",
      "\n",
      "All the weights of AutoencoderDC were initialized from the model checkpoint at /teamspace/studios/this_studio/.cache/huggingface/hub/models--Efficient-Large-Model--Sana_1600M_1024px_diffusers/snapshots/d1b54936033cd7d45410ecadd692c5c502a19a38/vae.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderDC for predictions without further training.\n",
      "Loaded vae as AutoencoderDC from `vae` subfolder of Efficient-Large-Model/Sana_1600M_1024px_diffusers.\n",
      "\n",
      "Loading pipeline components...:  80%|██████████▍  | 4/5 [00:04<00:01,  1.07s/it]\u001b[ALoaded tokenizer as GemmaTokenizerFast from `tokenizer` subfolder of Efficient-Large-Model/Sana_1600M_1024px_diffusers.\n",
      "\n",
      "Loading pipeline components...: 100%|█████████████| 5/5 [00:05<00:00,  1.13s/it]\u001b[A\n",
      "09/20/2025 18:48:56 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A worker wearing helmet, gloves, and safety vest performing maintenance on industrial equipment outdoors. The worker is handling insulators and electrical connections on high-voltage equipment, standing on scaffolding with proper PPE observed.\n",
      "Steps:  85%|█████████▍ | 1500/1760 [12:56<02:05,  2.07it/s, loss=0.992, lr=5e-5]09/20/2025 18:52:03 - INFO - accelerate.accelerator - Saving current state to /teamspace/studios/this_studio/output_40/trained-sana-lora/checkpoint-1500\n",
      "Model weights saved in /teamspace/studios/this_studio/output_40/trained-sana-lora/checkpoint-1500/pytorch_lora_weights.safetensors\n",
      "09/20/2025 18:52:03 - INFO - accelerate.checkpointing - Optimizer state saved in /teamspace/studios/this_studio/output_40/trained-sana-lora/checkpoint-1500/optimizer.bin\n",
      "09/20/2025 18:52:03 - INFO - accelerate.checkpointing - Scheduler state saved in /teamspace/studios/this_studio/output_40/trained-sana-lora/checkpoint-1500/scheduler.bin\n",
      "09/20/2025 18:52:03 - INFO - accelerate.checkpointing - Sampler state for dataloader 0 saved in /teamspace/studios/this_studio/output_40/trained-sana-lora/checkpoint-1500/sampler.bin\n",
      "09/20/2025 18:52:03 - INFO - accelerate.checkpointing - Random states saved in /teamspace/studios/this_studio/output_40/trained-sana-lora/checkpoint-1500/random_states_0.pkl\n",
      "09/20/2025 18:52:03 - INFO - __main__ - Saved state to /teamspace/studios/this_studio/output_40/trained-sana-lora/checkpoint-1500\n",
      "Steps: 100%|████████████| 1760/1760 [15:04<00:00,  2.11it/s, loss=1.09, lr=5e-5]Model weights saved in /teamspace/studios/this_studio/output_40/trained-sana-lora/pytorch_lora_weights.safetensors\n",
      "\n",
      "Loading pipeline components...:   0%|                     | 0/5 [00:00<?, ?it/s]\u001b[A{'use_dynamic_shifting', 'time_shift_type'} was not found in config. Values will be initialized to default values.\n",
      "Loaded scheduler as DPMSolverMultistepScheduler from `scheduler` subfolder of Efficient-Large-Model/Sana_1600M_1024px_diffusers.\n",
      "Instantiating SanaTransformer2DModel model under default dtype torch.float32.\n",
      "{'interpolation_scale', 'guidance_embeds_scale', 'timestep_scale', 'guidance_embeds', 'qk_norm'} was not found in config. Values will be initialized to default values.\n",
      "\n",
      "\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:00<00:00, 58.11it/s]\u001b[A\u001b[A\n",
      "All model checkpoint weights were used when initializing SanaTransformer2DModel.\n",
      "\n",
      "All the weights of SanaTransformer2DModel were initialized from the model checkpoint at /teamspace/studios/this_studio/.cache/huggingface/hub/models--Efficient-Large-Model--Sana_1600M_1024px_diffusers/snapshots/d1b54936033cd7d45410ecadd692c5c502a19a38/transformer.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use SanaTransformer2DModel for predictions without further training.\n",
      "Loaded transformer as SanaTransformer2DModel from `transformer` subfolder of Efficient-Large-Model/Sana_1600M_1024px_diffusers.\n",
      "\n",
      "Loading pipeline components...:  40%|█████▏       | 2/5 [00:00<00:00,  9.74it/s]\u001b[A\n",
      "\n",
      "Loading checkpoint shards:   0%|                          | 0/2 [00:00<?, ?it/s]\u001b[A\u001b[A\n",
      "\n",
      "Loading checkpoint shards:  50%|█████████         | 1/2 [00:03<00:03,  3.72s/it]\u001b[A\u001b[A\n",
      "\n",
      "Loading checkpoint shards: 100%|██████████████████| 2/2 [00:03<00:00,  1.98s/it]\u001b[A\u001b[A\n",
      "Loaded text_encoder as Gemma2Model from `text_encoder` subfolder of Efficient-Large-Model/Sana_1600M_1024px_diffusers.\n",
      "\n",
      "Loading pipeline components...:  60%|███████▊     | 3/5 [00:04<00:03,  1.72s/it]\u001b[AInstantiating AutoencoderDC model under default dtype torch.float32.\n",
      "{'decoder_conv_act_fn', 'decoder_in_shortcut', 'encoder_out_shortcut'} was not found in config. Values will be initialized to default values.\n",
      "All model checkpoint weights were used when initializing AutoencoderDC.\n",
      "\n",
      "All the weights of AutoencoderDC were initialized from the model checkpoint at /teamspace/studios/this_studio/.cache/huggingface/hub/models--Efficient-Large-Model--Sana_1600M_1024px_diffusers/snapshots/d1b54936033cd7d45410ecadd692c5c502a19a38/vae.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use AutoencoderDC for predictions without further training.\n",
      "Loaded vae as AutoencoderDC from `vae` subfolder of Efficient-Large-Model/Sana_1600M_1024px_diffusers.\n",
      "\n",
      "Loading pipeline components...:  80%|██████████▍  | 4/5 [00:04<00:01,  1.17s/it]\u001b[ALoaded tokenizer as GemmaTokenizerFast from `tokenizer` subfolder of Efficient-Large-Model/Sana_1600M_1024px_diffusers.\n",
      "\n",
      "Loading pipeline components...: 100%|█████████████| 5/5 [00:05<00:00,  1.07s/it]\u001b[A\n",
      "Loading transformer.\n",
      "09/20/2025 18:54:19 - INFO - __main__ - Running validation... \n",
      " Generating 4 images with prompt: A worker wearing helmet, gloves, and safety vest performing maintenance on industrial equipment outdoors. The worker is handling insulators and electrical connections on high-voltage equipment, standing on scaffolding with proper PPE observed.\n",
      "Steps: 100%|████████████| 1760/1760 [15:24<00:00,  1.90it/s, loss=1.09, lr=5e-5]\n"
     ]
    }
   ],
   "source": [
    "!accelerate launch train_dreambooth_lora_sana.py \\\n",
    "  --pretrained_model_name_or_path=\"Efficient-Large-Model/Sana_1600M_1024px_diffusers\" \\\n",
    "  --instance_data_dir=\"/teamspace/studios/this_studio/PPE_SANA/content/street-work-1/valid/images\" \\\n",
    "  --output_dir=\"/teamspace/studios/this_studio/output_40/trained-sana-lora\" \\\n",
    "  --mixed_precision=\"bf16\" \\\n",
    "  --instance_prompt=\"A factory worker wearing PPE performing tasks with machinery\" \\\n",
    "  --max_sequence_length=1024 \\\n",
    "  --resolution=512 \\\n",
    "  --train_batch_size=4 \\\n",
    "  --gradient_accumulation_steps=1 \\\n",
    "  --gradient_checkpointing \\\n",
    "  --cache_latents \\\n",
    "  --lr_scheduler=\"constant\" \\\n",
    "  --learning_rate=5e-5 \\\n",
    "  --max_train_steps=1760 \\\n",
    "  --validation_prompt=\"A worker wearing helmet, gloves, and safety vest performing maintenance on industrial equipment outdoors. The worker is handling insulators and electrical connections on high-voltage equipment, standing on scaffolding with proper PPE observed\" \\\n",
    "  --validation_epochs=25 \\\n",
    "  --seed=0 \\\n",
    "  --report_to tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow installation not found - running with reduced feature set.\n",
      "\n",
      "NOTE: Using experimental fast data loading logic. To disable, pass\n",
      "    \"--load_fast=false\" and report issues on GitHub. More details:\n",
      "    https://github.com/tensorflow/tensorboard/issues/4784\n",
      "\n",
      "Serving TensorBoard on localhost; to expose to the network, use a proxy or pass --bind_all\n",
      "TensorBoard 2.15.1 at http://localhost:6006/ (Press CTRL+C to quit)\n",
      "^C\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir=\"/teamspace/studios/this_studio/output_40/trained-sana-lora/logs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
